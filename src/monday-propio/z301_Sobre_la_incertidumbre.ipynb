{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Eligiendo modelos con incertidumbre\n",
    "\n",
    "> All models are wrong, but some are useful.\n",
    "\n",
    "George Box\n",
    "\n",
    "> If you torture the data long enough, it will confess.\n",
    "\n",
    "Ronald Coase\n",
    "\n",
    "A esta altura de la maetria, el alumno ya debe saber lo importante que es no sub-ajustar, ni sobre-ajustar un modelo. Puede repasar los conceptos visualmente en el siguiente link http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
    "\n",
    "Para lograr esto, necesitamos \"construir\" el mejor modelo posible. Sin embargo, esto nos plantea dos preguntas clave:\n",
    "* ¿qué significa construir un modelo?\n",
    "* Y, en segundo lugar, si tenemos dos modelos, ¿cómo determinamos cuál es el mejor?\n",
    "\n",
    "Empecemos realizando una comparación entre el modelo por defecto  de **árboles de decisión** (no controla el crecimiento) y uno levemente parametrizado.\n",
    "\n",
    "Levantemos el entorno e instalemos los paquetes que nos probablemente no dispongamos. Se usarán a lo largo de la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14392,
     "status": "ok",
     "timestamp": 1756154423254,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "oTlmka0Z7CA5",
    "outputId": "e1e2ac12-6737-4bf1-9e58-b9d7e66d7d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/augusto/.venv/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/augusto/.venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/augusto/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/augusto/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Requirement already satisfied: greenlet>=1 in /home/augusto/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/augusto/.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756154423278,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "x0IutZ5v4Pn5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from time import time\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_contour,  plot_slice, plot_optimization_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgrO4dvN0jCI"
   },
   "source": [
    "Notará a continuación que trabajaremos como mes de entrenamiento **Febrero** y reservaremos **Abril** solo para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 21322,
     "status": "ok",
     "timestamp": 1756154457370,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/home/augusto/Desktop/dmeyf2025/Data/'\n",
    "dataset_file = 'competencia_01.csv'\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "mes_train = 202102\n",
    "mes_test = 202104\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [0, 1, 2, 3, 4]\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UnYMoA1l4jJ3"
   },
   "outputs": [],
   "source": [
    "X = data[data['foto_mes'] == mes_train]\n",
    "y = X['clase_ternaria']\n",
    "X = X.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65j320lg1eth"
   },
   "source": [
    "Y necesitamos una función que nos ayude a calcular la ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TWHFFm431krP"
   },
   "outputs": [],
   "source": [
    "def ganancia(model, X, y, prop=1, threshold=0.025):\n",
    "\n",
    "  class_index = np.where(model.classes_ == \"BAJA+2\")[0][0]\n",
    "  y_hat = model.predict_proba(X)\n",
    "\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjQM00zh3FtS"
   },
   "source": [
    "Mira a continuación el siguiente código.\n",
    "\n",
    "* ¿Cuál cree que es el mejor modelo?\n",
    "* ¿Cuáles son los problemas que ve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47673,
     "status": "ok",
     "timestamp": 1756152501652,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "t_vb-tye2dw_",
    "outputId": "d8e976ee-44c1-4b0d-bb2d-ac967544989d"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m model_base = DecisionTreeClassifier(random_state=semillas[\u001b[32m0\u001b[39m])\n\u001b[32m      2\u001b[39m model_ale = DecisionTreeClassifier(criterion=\u001b[33m'\u001b[39m\u001b[33mgini\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m                                random_state=semillas[\u001b[32m0\u001b[39m],\n\u001b[32m      4\u001b[39m                                min_samples_split=\u001b[32m80\u001b[39m,\n\u001b[32m      5\u001b[39m                                max_depth=\u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel_base\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model_ale.fit(X,y)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGanancia de modelo Base: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mganancia(model_base,\u001b[38;5;250m \u001b[39mX,\u001b[38;5;250m \u001b[39my)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:1009\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    978\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    980\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    981\u001b[39m \n\u001b[32m    982\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:252\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    248\u001b[39m check_X_params = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    249\u001b[39m     dtype=DTYPE, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, force_all_finite=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    250\u001b[39m )\n\u001b[32m    251\u001b[39m check_y_params = \u001b[38;5;28mdict\u001b[39m(ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m missing_values_in_feature_mask = (\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_missing_values_in_feature_mask(X)\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/base.py:648\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mestimator\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[32m    647\u001b[39m         check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    650\u001b[39m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1049\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1044\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1045\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1046\u001b[39m     )\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1058\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:126\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:175\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    161\u001b[39m     msg_err += (\n\u001b[32m    162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "model_base = DecisionTreeClassifier(random_state=semillas[0])\n",
    "model_ale = DecisionTreeClassifier(criterion='gini',\n",
    "                               random_state=semillas[0],\n",
    "                               min_samples_split=80,\n",
    "                               max_depth=5)\n",
    "\n",
    "model_base.fit(X,y)\n",
    "model_ale.fit(X,y)\n",
    "\n",
    "print(f\"Ganancia de modelo Base: {ganancia(model_base, X, y)}\")\n",
    "print(f\"Ganancia de modelo Ale: {ganancia(model_ale, X, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxS0uXMz3PuY"
   },
   "source": [
    "* ¿Cómo se pueden solucionar?\n",
    "\n",
    "Dado que lo que hicimos no pinta nada bien, pasemos a una de las herramientas que separa la ciencia de datos de la estadística tradicional\n",
    "\n",
    "* ¿Por qué separamos en train/test?\n",
    "* ¿Cómo funciona la estadística tradicional?\n",
    "* Son números aleatorios los que nos dan las computadoras\n",
    "* ¿Por qué usamos semillas?\n",
    "* ¿Qué es una partición estratificada?\n",
    "* ¿Es realmente en nuestro caso una partición estratificada?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viSb47YW6jIK"
   },
   "source": [
    "Veamos alguna de las formas de separar los conjuntos de datos para medir su calidad:\n",
    "\n",
    "* **Train-Test Split**: Divide el conjunto de datos en dos partes: un conjunto de entrenamiento y otro de prueba. El conjunto de entrenamiento se utiliza para ajustar el modelo, y el conjunto de prueba para evaluar su rendimiento.\n",
    "\n",
    "* **K-Fold Cross Validation**: Divide los datos en k subconjuntos o folds. El modelo se entrena k veces, cada vez utilizando k-1 subconjuntos como entrenamiento y el subconjunto restante como prueba. Esto se repite hasta que cada subconjunto se haya utilizado como conjunto de prueba una vez.\n",
    "\n",
    "* **Shuffle Split** (aka Montecarlo Cross Validation): Genera múltiples particiones aleatorias de los datos en conjuntos de entrenamiento y prueba. A diferencia de K-Fold, no garantiza que todos los puntos de datos sean utilizados en alguna iteración.\n",
    "\n",
    "En la cátedra preferimos usar está última, pero el alumno es libre de usar la que considera conveniente.\n",
    "\n",
    "Armemos ahora nuevamente los modelos anteriores, pero utilizando estas particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZGS36pPLM-O"
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=20,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "# Función que paraleliza la construcción de árboles de decisión\n",
    "def train_and_evaluate(train_index, test_index, params, X, y):\n",
    "  m = DecisionTreeClassifier(**params)\n",
    "  m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "  # Note que con el parámetro prop se corrige la distorsión por sampleo de la\n",
    "  # ganancia\n",
    "  ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "  return m, ganancia_value\n",
    "\n",
    "modelo_base_param = {\"random_state\":semillas[0]}\n",
    "\n",
    "modelo_ale_param = {\"criterion\": 'gini',\n",
    "                     \"random_state\":semillas[0],\n",
    "                     \"min_samples_split\":80,\n",
    "                     \"max_depth\":5,\n",
    "}\n",
    "\n",
    "results_base = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_base_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n",
    "\n",
    "results_ale = Parallel(n_jobs=-1)(\n",
    "    delayed(train_and_evaluate)(train_index, test_index, modelo_ale_param, X, y)\n",
    "    for train_index, test_index in sss.split(X, y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICS3PBYI71h_"
   },
   "source": [
    "Estamos haciendo por cada juego de parámetros 20 modelos. Esto no suele ser lo habitual. Con 5 se puede conseguir buenos resultados.\n",
    "\n",
    "Vamos a ver que tan bien le fue a los modelos en los conjuntos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1756153312257,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "PxNSRwQT8-ZR",
    "outputId": "854556f2-3124-4528-b68c-5ab2e7b90ccc"
   },
   "outputs": [],
   "source": [
    "ganancias_modelos_base = [result[1] for result in results_base]\n",
    "ganancias_modelos_ale = [result[1] for result in results_ale]\n",
    "\n",
    "df_pred = pd.DataFrame({'Ganancia': [result[1] for result in results_base], 'Modelo': 'Base'})\n",
    "df_pred2 = pd.DataFrame({'Ganancia': [result[1] for result in results_ale], 'Modelo': 'Ale'})\n",
    "df_combined = pd.concat([df_pred, df_pred2])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI6se0-A-xsL"
   },
   "source": [
    "* ¿Qué tan distintos son de los primero valores calculados con el modelo completo?\n",
    "* ¿Con cuál se queda?\n",
    "* ¿Por qué se produce semejante dispersión?\n",
    "* ¿Cuál considera que es el \"valor real\"?\n",
    "\n",
    "Podemos mirar la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756153312258,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "weA6qiqe-FwA",
    "outputId": "e79f603b-b0fe-40c3-8cbb-29a296e5e8f2"
   },
   "outputs": [],
   "source": [
    "mean_base = df_combined[df_combined['Modelo'] == 'Base']['Ganancia'].mean()\n",
    "mean_ale = df_combined[df_combined['Modelo'] == 'Ale']['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base: {mean_base}\")\n",
    "print(f\"Ganancia media del modelo ale: {mean_ale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJatBPAU-67W"
   },
   "source": [
    "* Si no le gusta la media, como más puede elegir un modelo.\n",
    "\n",
    "> **La vida no es simple**  -- Alumno promedio de la maestría.\n",
    "\n",
    "Muy interesante, pero lo importante es que sucedería en el **futuro**. Por este motivo nos guardamos el mes de **Abril**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjooaKLHXkko"
   },
   "outputs": [],
   "source": [
    "X_futuro = data[data['foto_mes'] == mes_test]\n",
    "y_futuro = X_futuro['clase_ternaria']\n",
    "X_futuro = X_futuro.drop(columns=['clase_ternaria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsUTeSfM_goB"
   },
   "source": [
    "Sobre el mes de abril, debemos usar el modelo que se entreno sobre todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1756153312748,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "h4FixjUZ7owV",
    "outputId": "3b497e5a-4c6f-4993-ee1e-9995a2fb25e0"
   },
   "outputs": [],
   "source": [
    "ganancia_junio_base = ganancia(model_base, X_futuro, y_futuro)\n",
    "ganancia_junio_ale = ganancia(model_ale, X_futuro, y_futuro)\n",
    "\n",
    "print(f\"Ganancia de modelo Base en Junio: {ganancia_junio_base}\")\n",
    "print(f\"Ganancia de modelo Ale en Junio: {ganancia_junio_ale}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQM8zroBBTjG"
   },
   "source": [
    "* ¿Cuál es mejor?\n",
    "* ¿Por qué cree que el mejor es el mejor?\n",
    "* ¿Hubiera elegido sabiamente únicamente con los datos de **Febrero**?\n",
    "\n",
    "El mundo es un lugar **cruel** para los data scientists. El escenario anterior tampoco es el presente para los alumnos. Ya que **kaggle** divide el dataset en una parte **pública** y otra **privada**. Simulemos los efectos que produce en la decisión del mejor modelo en los leaderboards, simulando varios a la vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoUgUIam8ASR"
   },
   "outputs": [],
   "source": [
    "# podemos tomar más muestras, dado que solo vamos a scorear y eso es más rápido\n",
    "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "\n",
    "ganancias_futuro_privada_ale = []\n",
    "ganancias_futuro_privada_base = []\n",
    "ganancias_futuro_publica_ale = []\n",
    "ganancias_futuro_publica_base = []\n",
    "\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_privada_ale.append(ganancia(model_ale, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_privada_base.append(ganancia(model_base, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "  ganancias_futuro_publica_ale.append(ganancia(model_ale, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_publica_base.append(ganancia(model_base, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "4UTGsLzKE5vQ",
    "outputId": "3570a350-5f47-422a-9caf-34b9bf2a1d29"
   },
   "outputs": [],
   "source": [
    "df_pred_1_ale = pd.DataFrame({'Ganancia': ganancias_futuro_privada_ale, 'Modelo': 'ale', 'Grupo': 'Privado'})\n",
    "df_pred_2_ale = pd.DataFrame({'Ganancia': ganancias_futuro_publica_ale, 'Modelo': 'ale', 'Grupo': 'Publico'})\n",
    "df_pred_1_base = pd.DataFrame({'Ganancia': ganancias_futuro_privada_base, 'Modelo': 'Base', 'Grupo': 'Privado'})\n",
    "df_pred_2_base = pd.DataFrame({'Ganancia': ganancias_futuro_publica_base, 'Modelo': 'Base', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base, df_pred_2_base, df_pred_1_ale, df_pred_2_ale ])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756153352192,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "0p7Po1I7FlL6",
    "outputId": "e68566cc-6cdf-46be-e3cf-58c2a2643de4"
   },
   "outputs": [],
   "source": [
    "mean_base_privado = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_base_publico = df_combined[(df_combined['Modelo'] == 'Base') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "mean_ale_privado = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Privado')]['Ganancia'].mean()\n",
    "mean_ale_publico = df_combined[(df_combined['Modelo'] == 'ale') & (df_combined['Grupo'] == 'Publico')]['Ganancia'].mean()\n",
    "\n",
    "print(f\"Ganancia media del modelo base en privado: {mean_base_privado}\")\n",
    "print(f\"Ganancia media del modelo base en publico: {mean_base_publico}\")\n",
    "print(f\"Ganancia media del modelo ale en privado: {mean_ale_privado}\")\n",
    "print(f\"Ganancia media del modelo ale en publico: {mean_ale_publico}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw0NeIfOG77K"
   },
   "source": [
    "* ¿Que significa todo esto?\n",
    "\n",
    "Bueno, dos cosas.\n",
    "\n",
    "* El modelo ale, es un caso de **vagancia**. Cambiar 2 parámetros y esperar un cambio radical no es lo más inteligente que se puede hacer. Realmente hay que hacer un esfuerzo para separar las distribuciones.\n",
    "* Aún así elegir un modelo no es una tarea simple que se pueda hacer con una **certeza** absoluta.\n",
    "\n",
    "Para mejorar los modelos, una paso adecuado es la búsqueda de hiperparámetros. Podemos contar con las siguientes técnicas de búsqueda de parámetros:\n",
    "\n",
    "* **Grid Search**: Explora exhaustivamente todas las combinaciones posibles de hiperparámetros dentro de un conjunto predefinido de valores. Aunque es exhaustivo.\n",
    "\n",
    "* **Random Search**: En lugar de probar todas las combinaciones posibles, selecciona un número aleatorio de combinaciones de hiperparámetros dentro de un rango predefinido.\n",
    "\n",
    "* **Bayesian Optimization**: Este método construye un modelo probabilístico del rendimiento de los hiperparámetros y utiliza ese modelo para seleccionar los valores de hiperparámetros más prometedores.\n",
    "\n",
    "* **Tree-structured Parzen Estimator (TPE)**: Una variante de la optimización bayesiana que utiliza estimadores de densidad basados en árboles (Parzen estimators) para modelar la probabilidad de los hiperparámetros óptimos. Es eficiente en la exploración de espacios de hiperparámetros complejos y se adapta bien a configuraciones con interdependencias entre los parámetros.\n",
    "\n",
    "* **Genetic Algorithms**: Emplea principios de la evolución natural, como selección, cruce y mutación, para encontrar combinaciones óptimas de hiperparámetros. Es útil en espacios de búsqueda complejos, aunque puede ser computacionalmente costoso.\n",
    "\n",
    "Repasemos en clase de que se trata cada uno. (tome notas)\n",
    "\n",
    "Todos nos buenas opciones para la búsqueda de ... nah mentira, **grid search** apesta, si no me cree calcule el tiempo necesario para barrer el dominio de búsqueda.\n",
    "\n",
    "Para la búsquedas de parámetros usaremos **Optuna**. **Optuna** es una librería poderosa y flexible, diseñada para realizar búsquedas eficientes y automatizadas.\n",
    "\n",
    "* Utiliza casi todos los álgoritmos mencionados y más.\n",
    "\n",
    "* Permite definir espacios de búsqueda complejos, incluyendo hiperparámetros categóricos, continuos, discretos y con dependencias condicionales.\n",
    "\n",
    "* Ofrece un mecanismo de pruning o poda, que permite detener evaluaciones de configuraciones de hiperparámetros que no muestran promesas tempranas.\n",
    "\n",
    "* Facilidad de Uso y Configuración.\n",
    "\n",
    "* Proporciona herramientas de visualización integradas para analizar el progreso de la optimización, visualizar la importancia de los hiperparámetros y explorar las configuraciones probadas.\n",
    "\n",
    "Buscaremos un mejor modelo de manera inteligente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1756154485445,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "85WbW6qroyfn",
    "outputId": "2277d434-f4cf-49f7-8f94-2ae30819a5ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "sss_opt = ShuffleSplit(n_splits=5, test_size=0.3, random_state=semillas[1])\n",
    "\n",
    "def objective(trial, X, y, sss):\n",
    "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 200)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "  max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 20)\n",
    "\n",
    "  def train_and_evaluate(train_index, test_index, X, y):\n",
    "    m = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=semillas[0],\n",
    "    )\n",
    "    m.fit(X.iloc[train_index],y.iloc[train_index])\n",
    "    ganancia_value = ganancia(m, X.iloc[test_index], y.iloc[test_index], prop=0.3)\n",
    "    return ganancia_value\n",
    "\n",
    "  results = Parallel(n_jobs=-1)(\n",
    "      delayed(train_and_evaluate)(train_index, test_index, X, y)\n",
    "      for train_index, test_index in sss.split(X)\n",
    "  )\n",
    "\n",
    "  return np.mean(results)\n",
    "\n",
    "storage_name = \"sqlite:////content/drive/MyDrive/Datos/optimization_tree.db\"\n",
    "study_name = \"exp_101_decision-tree-opt\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pLQD79dbP9P"
   },
   "source": [
    "Entre la muchas ventajas que tiene **Optuna** es que va almacenando las exploraciones en una base de datos, lo que nos permite continuar la búsqueda si esta se interrumpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2656571,
     "status": "ok",
     "timestamp": 1756157165375,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "Ba56plD9bLup",
    "outputId": "1397baa5-de08-468b-b2f8-f21c3ea4898f"
   },
   "outputs": [],
   "source": [
    "# No quiero que se ejecute automaticamente\n",
    "study.optimize(lambda trial: objective(trial, X, y, sss_opt), n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM8WsVYMcE6M"
   },
   "source": [
    "A continuación veremos como fue el proceso de búsqueda a través de las visualizaciones que cuenta la herramienta (los gráficos son bastante autoexplicativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1756157165859,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "wJ9-4XqG64AD",
    "outputId": "670ed9ca-6f61-4d1a-95b9-53c36985a7e0"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1756157166571,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "C4o1mz-b53_Q",
    "outputId": "fc2c73da-8394-4be6-f4b4-81b857b3f016"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1756157166933,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "XhcFEzRB62J2",
    "outputId": "acf83e4a-68d0-4c5c-f885-182e1afe57a0"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1756157167575,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "ZXGkSPR46pzy",
    "outputId": "d13a8015-1cd6-4037-bf25-0bc1403a44ae"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756157167587,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "KIu_VjPn-LrW",
    "outputId": "d4e450cf-bc47-420d-dd0d-b3299e709404"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=[\"max_depth\", \"max_leaf_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYy1gCarctOm"
   },
   "source": [
    "Pasemos a analizar como le fue al mejor modelo en **Abril**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10572,
     "status": "ok",
     "timestamp": 1756157178159,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "qX8GEf5M7aH1",
    "outputId": "98873d24-c3e7-442a-915c-3d3f6f9730ad"
   },
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_trial = study.best_trial\n",
    "best_model_params = best_trial.params\n",
    "print(\"Mejor modelo:\", best_model_params)\n",
    "\n",
    "model_best = DecisionTreeClassifier(**best_model_params, random_state=semillas[0])\n",
    "model_best.fit(X, y)\n",
    "\n",
    "print(f\"Ganancia del mejor modelo: {ganancia(model_best, X_futuro, y_futuro)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yK8LBJVeD8R"
   },
   "source": [
    "Es mejor que los anteriores! y solo por una hora de procesamiento!!!\n",
    "\n",
    "¿qué más podemos pedir por tan poco?\n",
    "\n",
    "Veamos comparados con los anteriores que tanto mejor es...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 22382,
     "status": "ok",
     "timestamp": 1756157200544,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "kRWjXvFWTTdL",
    "outputId": "d55c55a0-58a8-4ebd-c218-b76484b5cb82"
   },
   "outputs": [],
   "source": [
    "ganancias_futuro_top0_publica = []\n",
    "ganancias_futuro_top0_privado = []\n",
    "for train_index, test_index in sss_futuro.split(X_futuro, y_futuro):\n",
    "  ganancias_futuro_top0_publica.append(ganancia(model_best, X_futuro.iloc[test_index], y_futuro.iloc[test_index], prop=0.3))\n",
    "  ganancias_futuro_top0_privado.append(ganancia(model_best, X_futuro.iloc[train_index], y_futuro.iloc[train_index], prop=0.7))\n",
    "\n",
    "df_pred_top0_privado = pd.DataFrame({'Ganancia': ganancias_futuro_top0_privado, 'Modelo': 'top0', 'Grupo': 'Privado'})\n",
    "df_pred_top0_publica = pd.DataFrame({'Ganancia': ganancias_futuro_top0_publica, 'Modelo': 'top0', 'Grupo': 'Publico'})\n",
    "\n",
    "df_combined = pd.concat([df_pred_1_base,\n",
    "                         df_pred_2_base,\n",
    "                         df_pred_1_ale,\n",
    "                         df_pred_2_ale,\n",
    "                         df_pred_top0_privado,\n",
    "                         df_pred_top0_publica])\n",
    "\n",
    "g = sns.FacetGrid(df_combined, col=\"Grupo\", row=\"Modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"Ganancia\", kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djfNrxaXeaMa"
   },
   "source": [
    "Bueno, no parece mucho mejor. Es tan solo mejor. Vamos moviendo de a poco la vara.\n",
    "\n",
    "* ¿Qué se puede hacer para mejorarlo? Debate con la clase abierta\n",
    "\n",
    "Una última cosa, solo de pura maldad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28500,
     "status": "ok",
     "timestamp": 1756157229043,
     "user": {
      "displayName": "Joaquín Sebastian Tschopp",
      "userId": "12463161021212811365"
     },
     "user_tz": 180
    },
    "id": "jZ7r-UOgSw58",
    "outputId": "d04f26d1-03c4-4e2f-cb2a-a7731d3deebf"
   },
   "outputs": [],
   "source": [
    "n_top_models = 3\n",
    "top_trials = study.best_trials[0:n_top_models]\n",
    "\n",
    "top_models = []\n",
    "for i, trial in enumerate(top_trials):\n",
    "     model_params = trial.params\n",
    "     print(f\"Top {i}: {model_params}\")\n",
    "     model = DecisionTreeClassifier(**model_params, random_state=semillas[0])\n",
    "     model.fit(X, y)\n",
    "     top_models.append(model)\n",
    "\n",
    "ganancias_abril = []\n",
    "for model in top_models:\n",
    "  ganancias_abril.append(ganancia(model, X_futuro, y_futuro))\n",
    "\n",
    "for i, ganancia_abril in enumerate(ganancias_abril):\n",
    "  print(f\"Ganancia de top {i} en abril: {ganancia_abril}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk_3Fuly0vmI"
   },
   "source": [
    "## Tarea:\n",
    "\n",
    "* Envíos a Kaggle:\n",
    " * Defina los mejores parámetros para realizar una búsqueda.\n",
    " * Explore la configuración de Optuna para una mejor búsqueda.\n",
    " * Arme un script que tome la salida de un modelo y genere un archivo para Kaggle.\n",
    " * Entrena el modelo usando datos de febrero y mirando su rendimiento en abril.  \n",
    "   * Prueba el modelo completo entrenado en febrero, score en Junio y suba a  Kaggle.\n",
    "   * El modelo seleccionado se reentrena con los datos de abril y se scorea en junio para kaggle\n",
    "* Busca el mejor modelo en abril y scoree en junio para Kaggle.\n",
    "\n",
    "¿Cuál fue su mejor predicción?\n",
    "\n",
    "Colaboración:\n",
    "* Recuerde compartir con tus compañeros los nuevos scripts que hayas generado y las configuraciones que hayas probado por el canal de"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
